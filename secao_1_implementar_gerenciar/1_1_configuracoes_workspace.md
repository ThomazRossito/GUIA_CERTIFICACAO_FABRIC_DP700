# 1.1 Definir as configura√ß√µes do workspace do Microsoft Fabric

A configura√ß√£o adequada de um workspace no Microsoft Fabric √© a base para a implementa√ß√£o de uma solu√ß√£o de an√°lise de dados robusta, bem governada e otimizada. Esta se√ß√£o aborda em profundidade as configura√ß√µes essenciais para os diferentes componentes de um workspace, garantindo que o ambiente esteja preparado para desempenho, seguran√ßa, colabora√ß√£o e escalabilidade.

## Vis√£o Geral da Hierarquia do Fabric

Antes de mergulhar nas configura√ß√µes espec√≠ficas, √© fundamental entender a hierarquia organizacional do Microsoft Fabric:

```mermaid
graph TD
    A[Tenant Microsoft 365] --> B[Capacity F2/F4/F8/F16...]
    B --> C[Workspace 1]
    B --> D[Workspace 2]
    B --> E[Workspace N]
    C --> F[Lakehouse]
    C --> G[Data Warehouse]
    C --> H[Pipeline]
    C --> I[Notebook]
    C --> J[Dataflow Gen2]
    C --> K[Eventstream]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#e8f5e9
    style F fill:#f3e5f5
    style G fill:#f3e5f5
    style H fill:#f3e5f5
```

**Componentes da Hierarquia:**

- **Tenant**: Sua organiza√ß√£o Microsoft 365
- **Capacity**: Recurso de computa√ß√£o dedicado (SKUs: F2, F4, F8, F16, F32, F64, F128, F256, F512, F1024, F2048)
- **Workspace**: Container l√≥gico para itens relacionados
- **Items**: Lakehouses, Warehouses, Pipelines, Notebooks, etc.

---

## 1. Configura√ß√µes do Workspace do Spark

As configura√ß√µes do Apache Spark no Microsoft Fabric s√£o **cr√≠ticas** para gerenciar o desempenho, custos e recursos dos seus trabalhos de engenharia de dados. Elas s√£o divididas em **Pools do Spark** e **Ambientes do Spark**.

### 1.1 Pools do Spark (Spark Pools)

Os Pools do Spark definem o **hardware** (infraestrutura de computa√ß√£o) no qual seus trabalhos Spark ser√£o executados.

#### Componentes de um Pool do Spark

| Componente | Descri√ß√£o | Op√ß√µes Dispon√≠veis |
|------------|-----------|-------------------|
| **Node Family** | Fam√≠lia de hardware dos n√≥s | Memory Optimized, Compute Optimized, GPU Optimized |
| **Node Size** | Tamanho de cada n√≥ | Small, Medium, Large, X-Large, XX-Large |
| **Autoscale** | Escalonamento autom√°tico de n√≥s | Min nodes, Max nodes |
| **Dynamic Allocation** | Aloca√ß√£o din√¢mica de executores | Habilitado por padr√£o |

#### Node Families - Compara√ß√£o Detalhada

| Node Family | Quando Usar | Caracter√≠sticas | Casos de Uso T√≠picos |
|-------------|-------------|-----------------|---------------------|
| **Memory Optimized** | Workloads que requerem muita mem√≥ria | Alta propor√ß√£o mem√≥ria/vCore (8:1) | - Grandes joins<br>- Agrega√ß√µes complexas<br>- Machine Learning<br>- Caching extensivo |
| **Compute Optimized** | Workloads balanceados | Propor√ß√£o equilibrada mem√≥ria/vCore (4:1) | - ETL geral<br>- Transforma√ß√µes padr√£o<br>- Processamento batch |
| **GPU Optimized** | Workloads de IA/ML intensivos | GPUs NVIDIA para computa√ß√£o paralela | - Deep Learning<br>- Processamento de imagens<br>- Treinamento de modelos |

#### Node Sizes - Especifica√ß√µes

| Size | vCores | Mem√≥ria | Quando Usar |
|------|--------|---------|-------------|
| Small | 4 | 32 GB | Desenvolvimento, testes, datasets pequenos (<10 GB) |
| Medium | 8 | 64 GB | Workloads de produ√ß√£o pequenos a m√©dios |
| Large | 16 | 128 GB | Workloads de produ√ß√£o m√©dios |
| X-Large | 32 | 256 GB | Workloads de produ√ß√£o grandes |
| XX-Large | 64 | 512 GB | Workloads muito grandes, processamento massivo |

#### Autoscale vs Dynamic Allocation

**Conceito Fundamental:**

```mermaid
graph LR
    A[Autoscale] -->|Gerencia| B[N√∫mero de N√≥s/M√°quinas]
    C[Dynamic Allocation] -->|Gerencia| D[N√∫mero de Executores por Job]
    
    style A fill:#ffebee
    style C fill:#e3f2fd
```

| Caracter√≠stica | Autoscale | Dynamic Allocation |
|----------------|-----------|-------------------|
| **O que gerencia** | N√∫mero de n√≥s (m√°quinas) no pool | N√∫mero de executores (processos) por job |
| **Escopo** | N√≠vel do Pool | N√≠vel do Job/Notebook |
| **Configura√ß√£o** | Min nodes: 1, Max nodes: 10 | Habilitado por padr√£o no Fabric |
| **Quando escala** | Baseado na demanda agregada do pool | Baseado nas necessidades do job espec√≠fico |
| **Benef√≠cio** | Otimiza√ß√£o de custo do pool | Otimiza√ß√£o de recursos por job |

**No Microsoft Fabric**: Cada n√≥ do pool corresponde a **um executor**, simplificando a gest√£o. Quando voc√™ configura Autoscale de 1-5 n√≥s, voc√™ ter√° de 1-5 executores dispon√≠veis.

#### Configura√ß√£o de Pool - Exemplo Pr√°tico

**Cen√°rio**: ETL de produ√ß√£o com workloads vari√°veis ao longo do dia

```
Pool Configuration:
‚îú‚îÄ‚îÄ Name: "Production_ETL_Pool"
‚îú‚îÄ‚îÄ Node Family: Memory Optimized
‚îú‚îÄ‚îÄ Node Size: Large (16 vCores, 128 GB)
‚îú‚îÄ‚îÄ Autoscale: Enabled
‚îÇ   ‚îú‚îÄ‚îÄ Min nodes: 2
‚îÇ   ‚îî‚îÄ‚îÄ Max nodes: 8
‚îî‚îÄ‚îÄ Dynamic Allocation: Enabled (default)
```

**Justificativa**:
- **Memory Optimized**: ETL com joins complexos
- **Large**: Balanceamento custo/performance
- **Min 2 nodes**: Garantir disponibilidade m√≠nima
- **Max 8 nodes**: Controlar custos, suportar picos

### 1.2 Ambientes do Spark (Spark Environments)

Os Ambientes do Spark definem o **software** (runtime e bibliotecas) dispon√≠vel para notebooks e jobs.

#### Componentes de um Ambiente

| Componente | Descri√ß√£o | Exemplo |
|------------|-----------|---------|
| **Spark Runtime** | Vers√£o do Apache Spark | Spark 3.4, Spark 3.5 |
| **Python Version** | Vers√£o do Python | Python 3.10, 3.11 |
| **Libraries** | Bibliotecas instaladas | pandas, scikit-learn, tensorflow |
| **Spark Properties** | Configura√ß√µes do Spark | spark.sql.adaptive.enabled=true |

#### Tipos de Bibliotecas

**1. Bibliotecas P√∫blicas (Public Libraries)**

```python
# Instala√ß√£o via PyPI
pip install pandas==2.0.0
pip install scikit-learn==1.3.0

# Instala√ß√£o via Conda
conda install -c conda-forge xgboost
```

**2. Bibliotecas Customizadas (Custom Libraries)**

- Upload de arquivos `.whl` (Python wheel)
- Upload de arquivos `.jar` (Java/Scala)
- Upload de arquivos `.tar.gz`

**3. Bibliotecas Inline (no Notebook)**

```python
# Instala√ß√£o tempor√°ria (apenas para a sess√£o atual)
%pip install package-name

# Instala√ß√£o com configura√ß√£o do Spark
%conda install package-name
```

#### Criando um Ambiente Customizado - Passo a Passo

**Cen√°rio**: Equipe de Data Science precisa de bibliotecas espec√≠ficas de ML

1. **Criar Novo Ambiente**:
   - Workspace Settings ‚Üí Spark ‚Üí Environments ‚Üí New Environment
   - Nome: "DataScience_ML_Environment"

2. **Selecionar Runtime**:
   - Spark Runtime: 3.5
   - Python Version: 3.11

3. **Adicionar Bibliotecas P√∫blicas**:
   ```
   scikit-learn==1.3.0
   xgboost==2.0.0
   lightgbm==4.0.0
   imbalanced-learn==0.11.0
   shap==0.42.0
   ```

4. **Adicionar Bibliotecas Customizadas**:
   - Upload: `company_ml_utils-1.0.0-py3-none-any.whl`

5. **Configurar Spark Properties**:
   ```properties
   spark.sql.adaptive.enabled=true
   spark.sql.adaptive.coalescePartitions.enabled=true
   spark.sql.adaptive.skewJoin.enabled=true
   ```

6. **Definir como Padr√£o do Workspace** (opcional)

#### Ambiente Padr√£o vs Ambiente Espec√≠fico

| Aspecto | Ambiente Padr√£o do Workspace | Ambiente Espec√≠fico do Item |
|---------|------------------------------|----------------------------|
| **Aplica√ß√£o** | Todos os notebooks/jobs do workspace | Apenas o notebook/job espec√≠fico |
| **Configura√ß√£o** | Workspace Settings ‚Üí Default Environment | Item Settings ‚Üí Environment |
| **Prioridade** | Menor | Maior (sobrescreve o padr√£o) |
| **Quando usar** | Bibliotecas comuns a todos os projetos | Requisitos espec√≠ficos de um projeto |

#### Best Practices - Ambientes do Spark

‚úÖ **DO (Fa√ßa)**:
- Versione seus ambientes (ex: `ML_Env_v1.0`, `ML_Env_v2.0`)
- Documente as bibliotecas e vers√µes usadas
- Use ambientes espec√≠ficos para projetos com requisitos √∫nicos
- Teste novos ambientes em workspace de desenvolvimento primeiro
- Mantenha ambientes enxutos (apenas bibliotecas necess√°rias)

‚ùå **DON'T (N√£o Fa√ßa)**:
- Instalar bibliotecas conflitantes
- Usar `%pip install` em produ√ß√£o (preferir ambiente configurado)
- Criar muitos ambientes similares (dificulta manuten√ß√£o)
- Esquecer de atualizar bibliotecas com vulnerabilidades de seguran√ßa

---

## 2. Configura√ß√µes do Workspace de Dom√≠nio

Os **Dom√≠nios** no Microsoft Fabric s√£o uma constru√ß√£o l√≥gica para agrupar workspaces que compartilham as mesmas necessidades de neg√≥cio, governan√ßa e propriedade. Eles s√£o fundamentais para implementar uma arquitetura de **Data Mesh**.

### Conceito de Data Mesh

```mermaid
graph TD
    A[Organiza√ß√£o] --> B[Dom√≠nio: Vendas]
    A --> C[Dom√≠nio: Marketing]
    A --> D[Dom√≠nio: Finan√ßas]
    A --> E[Dom√≠nio: RH]
    
    B --> B1[Workspace: Sales Analytics]
    B --> B2[Workspace: Sales Forecasting]
    
    C --> C1[Workspace: Campaign Analytics]
    C --> C2[Workspace: Customer Insights]
    
    D --> D1[Workspace: Financial Reporting]
    D --> D2[Workspace: Budget Planning]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#e8f5e9
    style D fill:#f3e5f5
    style E fill:#ffebee
```

### Configura√ß√µes de Dom√≠nio

#### 1. Cria√ß√£o de Dom√≠nio

**Requisitos**:
- Ser **Fabric Administrator** ou **Capacity Administrator**

**Passos**:
1. Admin Portal ‚Üí Domains ‚Üí Create Domain
2. Nome: "Sales_Domain"
3. Descri√ß√£o: "Dom√≠nio para todos os ativos de dados de vendas"
4. Imagem (opcional): Logo do departamento

#### 2. Atribui√ß√£o de Workspaces

**M√©todos**:

**A) Pelo Administrador do Dom√≠nio**:
- Domain Settings ‚Üí Workspaces ‚Üí Assign Workspaces
- Selecionar workspaces existentes

**B) Pelo Administrador do Workspace**:
- Workspace Settings ‚Üí Domain ‚Üí Request to join domain
- Aguardar aprova√ß√£o do Domain Admin

#### 3. Fun√ß√µes de Dom√≠nio

| Fun√ß√£o | Permiss√µes | Quando Atribuir |
|--------|-----------|-----------------|
| **Domain Admin** | - Gerenciar configura√ß√µes do dom√≠nio<br>- Aprovar/rejeitar solicita√ß√µes de workspace<br>- Atribuir Domain Contributors<br>- Definir pol√≠ticas de governan√ßa | L√≠deres de departamento, Data Governance team |
| **Domain Contributor** | - Solicitar adi√ß√£o de workspaces ao dom√≠nio<br>- Visualizar workspaces do dom√≠nio | Workspace Admins, Data Engineers do dom√≠nio |

### Benef√≠cios dos Dom√≠nios

1. **Descoberta de Dados**: Usu√°rios podem filtrar por dom√≠nio no OneLake Data Hub
2. **Governan√ßa Centralizada**: Pol√≠ticas aplicadas a todos os workspaces do dom√≠nio
3. **Ownership Claro**: Cada dom√≠nio tem propriet√°rios definidos
4. **Organiza√ß√£o L√≥gica**: Agrupa ativos relacionados ao neg√≥cio

---

## 3. Configura√ß√µes do Workspace do OneLake

O **OneLake** √© o "OneDrive para dados" do Microsoft Fabric - um √∫nico data lake l√≥gico para toda a organiza√ß√£o, baseado em ADLS Gen2.

### Arquitetura do OneLake

```mermaid
graph TD
    A[OneLake - Tenant Level] --> B[Workspace 1]
    A --> C[Workspace 2]
    
    B --> D[Lakehouse 1]
    B --> E[Warehouse 1]
    
    D --> F[Files]
    D --> G[Tables]
    
    F --> H[bronze/]
    F --> I[silver/]
    F --> J[gold/]
    
    style A fill:#0078d4
    style B fill:#e8f5e9
    style D fill:#fff4e1
```

### 3.1 Atalhos (Shortcuts)

Os **Shortcuts** permitem referenciar dados de outras fontes **sem copiar os dados**, promovendo reutiliza√ß√£o e evitando duplica√ß√£o.

#### Tipos de Shortcuts

| Tipo | Fonte | Quando Usar |
|------|-------|-------------|
| **OneLake Shortcut** | Outro Lakehouse/Warehouse no Fabric | Compartilhar dados entre workspaces/lakehouses |
| **ADLS Gen2 Shortcut** | Azure Data Lake Storage Gen2 | Acessar dados externos no Azure |
| **S3 Shortcut** | Amazon S3 | Acessar dados em AWS S3 |
| **Dataverse Shortcut** | Microsoft Dataverse | Integrar dados do Dynamics 365 |

#### Criando um Shortcut - Exemplo

**Cen√°rio**: Workspace de Analytics precisa acessar dados do Workspace de Engenharia

**Passos**:
1. Lakehouse Analytics ‚Üí Files ‚Üí New Shortcut
2. Tipo: OneLake
3. Selecionar:
   - Workspace: "Engineering_Workspace"
   - Lakehouse: "Raw_Data_Lakehouse"
   - Path: "Files/bronze/customers/"
4. Nome do Shortcut: "customers_bronze"

**Resultado**:
```
Lakehouse Analytics/
‚îî‚îÄ‚îÄ Files/
    ‚îî‚îÄ‚îÄ customers_bronze/ (shortcut ‚Üí Engineering_Workspace/Raw_Data_Lakehouse/Files/bronze/customers/)
```

#### Shortcuts vs C√≥pia de Dados

| Aspecto | Shortcuts | C√≥pia de Dados |
|---------|-----------|----------------|
| **Armazenamento** | Dados permanecem na fonte | Dados duplicados |
| **Custo** | Menor (sem duplica√ß√£o) | Maior (armazenamento duplicado) |
| **Atualiza√ß√£o** | Sempre dados atuais | Requer refresh |
| **Lat√™ncia** | Pode ter lat√™ncia de rede | Acesso local mais r√°pido |
| **Quando usar** | Dados de refer√™ncia, compartilhamento | Dados que precisam de transforma√ß√£o local |

### 3.2 Seguran√ßa do OneLake

A seguran√ßa no OneLake pode ser configurada em **m√∫ltiplos n√≠veis**:

```mermaid
graph TD
    A[Seguran√ßa OneLake] --> B[N√≠vel 1: Workspace]
    A --> C[N√≠vel 2: Item Lakehouse/Warehouse]
    A --> D[N√≠vel 3: Pasta/Arquivo]
    
    B --> B1[Workspace Roles: Admin, Member, Contributor, Viewer]
    C --> C1[Item Permissions: Read, ReadAll, ReadData, Write, Build]
    D --> D1[OneLake File Explorer: ACLs POSIX]
    
    style A fill:#ffebee
```

#### N√≠veis de Seguran√ßa

**1. Workspace Level**:
- Roles: Admin, Member, Contributor, Viewer
- Controla acesso a todos os itens do workspace

**2. Item Level (Lakehouse/Warehouse)**:
- Permissions: Read, ReadAll, ReadData, Write, Build
- Controla acesso ao item espec√≠fico

**3. File/Folder Level**:
- OneLake File Explorer: ACLs POSIX (rwx)
- Controle granular em pastas/arquivos espec√≠ficos

#### Exemplo de Configura√ß√£o de Seguran√ßa

**Cen√°rio**: Diferentes n√≠veis de acesso para diferentes equipes

```
Lakehouse: Sales_Data
‚îú‚îÄ‚îÄ Files/
‚îÇ   ‚îú‚îÄ‚îÄ bronze/          (Acesso: Data Engineers - RWX)
‚îÇ   ‚îú‚îÄ‚îÄ silver/          (Acesso: Data Engineers - RWX, Analysts - R-X)
‚îÇ   ‚îî‚îÄ‚îÄ gold/            (Acesso: Todos - R-X)
‚îî‚îÄ‚îÄ Tables/
    ‚îú‚îÄ‚îÄ dim_customers    (RLS aplicado)
    ‚îî‚îÄ‚îÄ fact_sales       (RLS aplicado)
```

**Configura√ß√£o**:
1. **Workspace Level**: Data Engineers = Member, Analysts = Viewer
2. **Item Level**: Lakehouse = ReadAll para Analysts
3. **Folder Level** (via OneLake File Explorer):
   - `bronze/`: ACL = Data Engineers (RWX)
   - `silver/`: ACL = Data Engineers (RWX), Analysts (R-X)
   - `gold/`: ACL = All Users (R-X)

---

## 4. Configura√ß√µes do Workspace do Fluxo de Trabalho de Dados

Os fluxos de trabalho de dados no Fabric s√£o representados por **Dataflows Gen2** e **Pipelines**.

### 4.1 Par√¢metros e Express√µes Din√¢micas

Permitem criar pipelines e dataflows **reutiliz√°veis** e **din√¢micos**.

#### Par√¢metros de Pipeline

**Exemplo**:
```json
{
  "parameters": {
    "SourcePath": {
      "type": "String",
      "defaultValue": "/bronze/sales/"
    },
    "ProcessDate": {
      "type": "String",
      "defaultValue": "2024-01-01"
    },
    "Environment": {
      "type": "String",
      "defaultValue": "DEV"
    }
  }
}
```

**Uso em Atividades**:
```
Copy Activity:
‚îú‚îÄ‚îÄ Source: @concat(parameters('SourcePath'), parameters('ProcessDate'))
‚îî‚îÄ‚îÄ Destination: @concat('/silver/sales_', parameters('ProcessDate'))
```

#### Express√µes do Sistema

| Fun√ß√£o | Descri√ß√£o | Exemplo |
|--------|-----------|---------|
| `utcnow()` | Data/hora atual UTC | `@utcnow()` ‚Üí "2024-01-15T10:30:00Z" |
| `adddays()` | Adicionar dias | `@adddays(utcnow(), -1)` ‚Üí Ontem |
| `formatDateTime()` | Formatar data | `@formatDateTime(utcnow(), 'yyyy-MM-dd')` ‚Üí "2024-01-15" |
| `concat()` | Concatenar strings | `@concat('prefix_', parameters('name'))` |
| `pipeline()` | Metadados do pipeline | `@pipeline().RunId` |

### 4.2 Agendamento e Gatilhos

#### Tipos de Triggers

| Tipo | Quando Usar | Configura√ß√£o |
|------|-------------|--------------|
| **Schedule Trigger** | Execu√ß√£o em hor√°rios fixos | Di√°rio √†s 2:00 AM, A cada hora |
| **Event-based Trigger** | Execu√ß√£o quando evento ocorre | Novo arquivo em pasta OneLake |
| **Manual Trigger** | Execu√ß√£o sob demanda | Bot√£o "Run" |

#### Schedule Trigger - Exemplos

**1. Execu√ß√£o Di√°ria**:
```
Schedule:
‚îú‚îÄ‚îÄ Frequency: Daily
‚îú‚îÄ‚îÄ Time: 02:00 AM
‚îî‚îÄ‚îÄ Timezone: (UTC-03:00) Bras√≠lia
```

**2. Execu√ß√£o a Cada Hora (Hor√°rio Comercial)**:
```
Schedule:
‚îú‚îÄ‚îÄ Frequency: Hourly
‚îú‚îÄ‚îÄ Interval: 1 hour
‚îú‚îÄ‚îÄ Start time: 08:00 AM
‚îî‚îÄ‚îÄ End time: 06:00 PM
```

**3. Execu√ß√£o Semanal**:
```
Schedule:
‚îú‚îÄ‚îÄ Frequency: Weekly
‚îú‚îÄ‚îÄ Days: Monday, Wednesday, Friday
‚îî‚îÄ‚îÄ Time: 06:00 AM
```

#### Event-based Trigger - Exemplo

**Cen√°rio**: Processar automaticamente quando novo arquivo chegar

```
Trigger Configuration:
‚îú‚îÄ‚îÄ Type: Storage events
‚îú‚îÄ‚îÄ Scope: OneLake
‚îú‚îÄ‚îÄ Lakehouse: "Raw_Data_Lakehouse"
‚îú‚îÄ‚îÄ Path: "/Files/bronze/incoming/"
‚îú‚îÄ‚îÄ Event: Blob created
‚îî‚îÄ‚îÄ File pattern: "*.csv"
```

**Quando um arquivo `sales_2024-01-15.csv` √© carregado em `/Files/bronze/incoming/`, o pipeline √© automaticamente acionado.**

---

## 5. Configura√ß√µes Gerais do Workspace

### 5.1 Workspace Settings

| Configura√ß√£o | Op√ß√µes | Descri√ß√£o |
|--------------|--------|-----------|
| **License Mode** | Trial, Premium Per User, Premium Per Capacity, Fabric Capacity | Tipo de licenciamento |
| **Workspace Description** | Texto livre | Descri√ß√£o do prop√≥sito do workspace |
| **Contact List** | E-mails | Contatos para suporte/quest√µes |
| **OneLake Storage** | Enabled/Disabled | Habilitar armazenamento OneLake |
| **Git Integration** | Azure DevOps, GitHub | Controle de vers√£o |
| **Default Lakehouse** | Selecionar Lakehouse | Lakehouse padr√£o para notebooks |

### 5.2 Workspace Access (Fun√ß√µes)

| Fun√ß√£o | Permiss√µes | Quando Atribuir |
|--------|-----------|-----------------|
| **Admin** | - Gerenciar workspace<br>- Gerenciar permiss√µes<br>- Deletar workspace<br>- Publicar/compartilhar conte√∫do | L√≠deres de projeto, Workspace owners |
| **Member** | - Criar/editar/deletar itens<br>- Publicar/compartilhar conte√∫do<br>- Executar notebooks/pipelines | Data Engineers, desenvolvedores |
| **Contributor** | - Criar/editar/deletar itens<br>- Executar notebooks/pipelines<br>- **N√ÉO pode** publicar/compartilhar | Data Engineers j√∫nior |
| **Viewer** | - Visualizar conte√∫do<br>- **N√ÉO pode** editar | Analistas, stakeholders |

---

## Best Practices - Configura√ß√µes de Workspace

### ‚úÖ Organiza√ß√£o

1. **Naming Conventions**:
   ```
   Workspace: [Department]_[Project]_[Environment]
   Exemplo: Sales_Analytics_PROD
   
   Pool: [Purpose]_[Size]_Pool
   Exemplo: ETL_Large_Pool
   
   Environment: [Team]_[Purpose]_Env_v[Version]
   Exemplo: DataScience_ML_Env_v1.0
   ```

2. **Separa√ß√£o de Ambientes**:
   - DEV, TEST, PROD em workspaces separados
   - Use Deployment Pipelines para promover entre ambientes

3. **Uso de Dom√≠nios**:
   - Agrupe workspaces relacionados em dom√≠nios
   - Facilita governan√ßa e descoberta

### ‚úÖ Seguran√ßa

1. **Princ√≠pio do Menor Privil√©gio**:
   - Atribua apenas as permiss√µes necess√°rias
   - Use Viewer sempre que poss√≠vel

2. **Revis√£o Peri√≥dica**:
   - Audite permiss√µes trimestralmente
   - Remova acessos de usu√°rios inativos

3. **Seguran√ßa em Camadas**:
   - Workspace ‚Üí Item ‚Üí Pasta/Arquivo
   - RLS/CLS para dados sens√≠veis

### ‚úÖ Performance

1. **Pools do Spark**:
   - Use Autoscale para otimizar custos
   - Escolha Node Family apropriado para workload
   - Min nodes = 1 para DEV, ‚â•2 para PROD

2. **Ambientes**:
   - Mantenha ambientes enxutos
   - Evite bibliotecas conflitantes
   - Versione ambientes

3. **Shortcuts**:
   - Prefira shortcuts a c√≥pias quando poss√≠vel
   - Use para dados de refer√™ncia compartilhados

### ‚úÖ Governan√ßa

1. **Documenta√ß√£o**:
   - Mantenha descri√ß√µes atualizadas
   - Documente prop√≥sito de cada workspace

2. **Controle de Vers√£o**:
   - Integre com Git (Azure DevOps/GitHub)
   - Use branches para desenvolvimento

3. **Monitoramento**:
   - Habilite logs de auditoria
   - Configure alertas para falhas

---

## Cen√°rios Pr√°ticos

### Cen√°rio 1: Configurar Workspace para ETL de Produ√ß√£o

**Requisitos**:
- Processar 500 GB de dados diariamente
- Joins complexos e agrega√ß√µes
- Equipe de 5 Data Engineers
- Ambiente de produ√ß√£o cr√≠tico

**Configura√ß√£o Recomendada**:

```
Workspace: Sales_ETL_PROD
‚îú‚îÄ‚îÄ License Mode: Fabric Capacity (F64)
‚îú‚îÄ‚îÄ Domain: Sales_Domain
‚îú‚îÄ‚îÄ Git Integration: Azure DevOps
‚îÇ
‚îú‚îÄ‚îÄ Spark Pool:
‚îÇ   ‚îú‚îÄ‚îÄ Name: "Production_ETL_Pool"
‚îÇ   ‚îú‚îÄ‚îÄ Node Family: Memory Optimized
‚îÇ   ‚îú‚îÄ‚îÄ Node Size: X-Large (32 vCores, 256 GB)
‚îÇ   ‚îú‚îÄ‚îÄ Autoscale: Min 2, Max 10
‚îÇ   ‚îî‚îÄ‚îÄ Dynamic Allocation: Enabled
‚îÇ
‚îú‚îÄ‚îÄ Spark Environment:
‚îÇ   ‚îú‚îÄ‚îÄ Name: "ETL_Prod_Env_v1.0"
‚îÇ   ‚îú‚îÄ‚îÄ Runtime: Spark 3.5
‚îÇ   ‚îú‚îÄ‚îÄ Libraries: delta-spark, pandas, pyarrow
‚îÇ   ‚îî‚îÄ‚îÄ Spark Properties:
‚îÇ       ‚îú‚îÄ‚îÄ spark.sql.adaptive.enabled=true
‚îÇ       ‚îî‚îÄ‚îÄ spark.sql.adaptive.skewJoin.enabled=true
‚îÇ
‚îú‚îÄ‚îÄ Access:
‚îÇ   ‚îú‚îÄ‚îÄ Admin: Data Engineering Lead
‚îÇ   ‚îú‚îÄ‚îÄ Member: 5 Data Engineers
‚îÇ   ‚îî‚îÄ‚îÄ Viewer: Business Stakeholders
‚îÇ
‚îî‚îÄ‚îÄ Triggers:
    ‚îî‚îÄ‚îÄ Schedule: Daily at 2:00 AM (UTC-3)
```

### Cen√°rio 2: Workspace de Data Science com ML

**Requisitos**:
- Treinamento de modelos de ML
- Bibliotecas espec√≠ficas (scikit-learn, xgboost, tensorflow)
- Experimenta√ß√£o e desenvolvimento
- GPU para deep learning

**Configura√ß√£o Recomendada**:

```
Workspace: DataScience_ML_DEV
‚îú‚îÄ‚îÄ License Mode: Fabric Capacity (F32)
‚îú‚îÄ‚îÄ Domain: Analytics_Domain
‚îÇ
‚îú‚îÄ‚îÄ Spark Pool:
‚îÇ   ‚îú‚îÄ‚îÄ Name: "ML_GPU_Pool"
‚îÇ   ‚îú‚îÄ‚îÄ Node Family: GPU Optimized
‚îÇ   ‚îú‚îÄ‚îÄ Node Size: Large
‚îÇ   ‚îú‚îÄ‚îÄ Autoscale: Min 1, Max 4
‚îÇ   ‚îî‚îÄ‚îÄ Dynamic Allocation: Enabled
‚îÇ
‚îú‚îÄ‚îÄ Spark Environment:
‚îÇ   ‚îú‚îÄ‚îÄ Name: "DataScience_ML_Env_v2.0"
‚îÇ   ‚îú‚îÄ‚îÄ Runtime: Spark 3.5
‚îÇ   ‚îú‚îÄ‚îÄ Python: 3.11
‚îÇ   ‚îî‚îÄ‚îÄ Libraries:
‚îÇ       ‚îú‚îÄ‚îÄ scikit-learn==1.3.0
‚îÇ       ‚îú‚îÄ‚îÄ xgboost==2.0.0
‚îÇ       ‚îú‚îÄ‚îÄ tensorflow==2.14.0
‚îÇ       ‚îú‚îÄ‚îÄ shap==0.42.0
‚îÇ       ‚îî‚îÄ‚îÄ mlflow==2.8.0
‚îÇ
‚îî‚îÄ‚îÄ Access:
    ‚îú‚îÄ‚îÄ Admin: Data Science Lead
    ‚îú‚îÄ‚îÄ Member: Data Scientists
    ‚îî‚îÄ‚îÄ Contributor: ML Engineers
```

---

## Refer√™ncias e Recursos

### Documenta√ß√£o Oficial Microsoft

1. [Microsoft Fabric Documentation](https://learn.microsoft.com/fabric/)
2. [Workspace Settings](https://learn.microsoft.com/fabric/data-engineering/workspace-admin-settings)
3. [Spark Compute Configuration](https://learn.microsoft.com/fabric/data-engineering/configure-spark-settings)
4. [OneLake Security](https://learn.microsoft.com/fabric/onelake/onelake-security)
5. [Domains in Fabric](https://learn.microsoft.com/fabric/governance/domains)
6. [Guia de Estudo DP-700](https://learn.microsoft.com/credentials/certifications/resources/study-guides/dp-700)

### Recursos Adicionais

- [Fabric Capacity Metrics App](https://learn.microsoft.com/fabric/enterprise/metrics-app)
- [OneLake File Explorer](https://learn.microsoft.com/fabric/onelake/onelake-file-explorer)
- [Deployment Pipelines](https://learn.microsoft.com/fabric/cicd/deployment-pipelines/intro-to-deployment-pipelines)

---

## Pontos-Chave para o Exame DP-700

üéØ **Memorize**:
- Diferen√ßa entre Autoscale (n√≥s) e Dynamic Allocation (executores)
- Node Families: Memory Optimized (8:1), Compute Optimized (4:1), GPU
- Workspace Roles: Admin > Member > Contributor > Viewer
- Item Permissions: Read, ReadAll, ReadData, Write, Build
- Shortcuts n√£o copiam dados, apenas referenciam
- Dom√≠nios s√£o para organiza√ß√£o l√≥gica e governan√ßa (Data Mesh)
- Ambientes definem software (runtime, bibliotecas)
- Pools definem hardware (n√≥s, mem√≥ria, vCores)

üéØ **Entenda**:
- Quando usar cada Node Family
- Como configurar seguran√ßa em m√∫ltiplos n√≠veis
- Diferen√ßa entre Schedule e Event-based triggers
- Quando usar Shortcuts vs C√≥pia de dados
- Hierarquia: Tenant ‚Üí Capacity ‚Üí Workspace ‚Üí Items
