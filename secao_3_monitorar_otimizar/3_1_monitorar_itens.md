# 3.1 Monitorar itens do Fabric

O monitoramento proativo √© uma disciplina **crucial** na engenharia de dados para garantir a **confiabilidade, desempenho e integridade** das solu√ß√µes de an√°lise. O Microsoft Fabric fornece ferramentas centralizadas e espec√≠ficas para monitorar a sa√∫de e o status de todos os itens, desde a ingest√£o at√© a entrega dos dados.

## Vis√£o Geral do Monitoramento

```mermaid
graph TD
    A[Monitoring Hub] --> B[Pipelines]
    A --> C[Dataflows]
    A --> D[Notebooks]
    A --> E[Semantic Models]
    
    B --> F[Alertas]
    C --> F
    D --> F
    E --> F
    
    F --> G[Data Activator]
    F --> H[Email]
    F --> I[Teams]
    
    style A fill:#e3f2fd
    style F fill:#fff4e1
    style G fill:#f3e5f5
```

---

## 1. Monitoring Hub

### 1.1 Vis√£o Geral

O **Monitoring Hub** √© o ponto centralizado para monitorar todas as execu√ß√µes no Fabric.

**Acesso**: Workspace ‚Üí Monitoring Hub (√≠cone de sino)

**O que monitora**:
- Pipelines
- Dataflows Gen2
- Notebooks
- Semantic Models (datasets)
- Spark Jobs

### 1.2 Informa√ß√µes Dispon√≠veis

| Informa√ß√£o | Descri√ß√£o |
|------------|-----------|
| **Status** | Succeeded, Failed, In Progress, Cancelled |
| **Dura√ß√£o** | Tempo total de execu√ß√£o |
| **In√≠cio/Fim** | Timestamps de in√≠cio e fim |
| **Triggered By** | Manual, Schedule, Event |
| **Run ID** | Identificador √∫nico da execu√ß√£o |

### 1.3 Filtros e Busca

```
Filtros dispon√≠veis:
- Item type (Pipeline, Dataflow, Notebook)
- Status (All, Succeeded, Failed, In Progress)
- Time range (Last 24 hours, Last 7 days, Custom)
- Item name (busca por nome)
```

---

## 2. Monitoramento de Pipelines

### 2.1 Detalhes da Execu√ß√£o

**Visualiza√ß√£o em √Årvore**:
```
Pipeline: Daily_Sales_ETL
‚îú‚îÄ‚îÄ Copy_Sales_Data (Succeeded, 2m 15s)
‚îú‚îÄ‚îÄ Transform_Sales_Notebook (Succeeded, 5m 30s)
‚îú‚îÄ‚îÄ Load_DW_StoredProc (Succeeded, 1m 45s)
‚îî‚îÄ‚îÄ Send_Success_Notification (Succeeded, 5s)
```

### 2.2 M√©tricas por Atividade

#### Copy Activity

| M√©trica | Descri√ß√£o |
|---------|-----------|
| **Rows Read** | N√∫mero de linhas lidas da fonte |
| **Rows Written** | N√∫mero de linhas escritas no destino |
| **Data Read** | Volume de dados lido (MB/GB) |
| **Data Written** | Volume de dados escrito |
| **Throughput** | MB/s |
| **Duration** | Tempo total |
| **Queued Duration** | Tempo em fila |
| **Transfer Duration** | Tempo de transfer√™ncia |

**Exemplo de Output**:
```json
{
  "rowsRead": 1500000,
  "rowsWritten": 1500000,
  "dataRead": 450.5,
  "dataWritten": 450.5,
  "throughput": 3.75,
  "duration": "00:02:00",
  "queuedDuration": "00:00:05",
  "transferDuration": "00:01:55"
}
```

#### Notebook Activity

| M√©trica | Descri√ß√£o |
|---------|-----------|
| **Spark Application ID** | ID da aplica√ß√£o Spark |
| **Duration** | Tempo total |
| **Executor Count** | N√∫mero de executors |
| **Executor Cores** | Cores por executor |
| **Executor Memory** | Mem√≥ria por executor |

### 2.3 Logs Detalhados

**Acessar Logs**:
1. Monitoring Hub ‚Üí Selecionar execu√ß√£o do pipeline
2. Clicar na atividade espec√≠fica
3. Aba "Output" ‚Üí Ver JSON completo
4. Aba "Details" ‚Üí Ver logs de erro

**Exemplo de Log de Erro**:
```
Error Code: 2200
Error Message: Failed to connect to source database
Details: Connection timeout after 30 seconds
Recommendation: Check network connectivity and firewall rules
```

---

## 3. Monitoramento de Dataflows

### 3.1 Refresh History

**Informa√ß√µes**:
- Status (Succeeded, Failed)
- Start time / End time
- Duration
- Rows processed
- Error message (se falhou)

### 3.2 Query Diagnostics

**Habilitar**:
1. Dataflow Gen2 ‚Üí Settings
2. Enable "Query diagnostics"
3. Pr√≥xima execu√ß√£o gerar√° logs detalhados

**O que captura**:
- Tempo de cada etapa do Power Query
- Opera√ß√µes de fold (query folding)
- Tempo de conex√£o com fonte
- Tempo de escrita no destino

### 3.3 M√©tricas de Performance

| M√©trica | O que Indica |
|---------|--------------|
| **Query Folding** | % de opera√ß√µes executadas na fonte |
| **Rows Processed** | Volume de dados |
| **Duration** | Tempo total |
| **Memory Usage** | Uso de mem√≥ria |

---

## 4. Monitoramento de Notebooks

### 4.1 Spark UI

**Acessar**:
1. Monitoring Hub ‚Üí Selecionar execu√ß√£o do notebook
2. Clicar em "Spark application"
3. Abre Spark UI completo

**Abas Principais**:

| Aba | O que Mostra |
|-----|--------------|
| **Jobs** | Lista de jobs Spark executados |
| **Stages** | Est√°gios de cada job |
| **Storage** | DataFrames cacheados |
| **Environment** | Configura√ß√µes do Spark |
| **Executors** | Status dos executors |
| **SQL** | Queries SQL executadas |

### 4.2 M√©tricas de Job

```
Job ID: 0
Description: show at <command-123>
Status: SUCCEEDED
Duration: 2.5 min
Stages: 3
Tasks: 200 (200 succeeded)
```

### 4.3 M√©tricas de Stage

| M√©trica | Descri√ß√£o |
|---------|-----------|
| **Input** | Dados lidos (MB) |
| **Output** | Dados escritos (MB) |
| **Shuffle Read** | Dados shuffled lidos |
| **Shuffle Write** | Dados shuffled escritos |
| **Duration** | Tempo do stage |
| **Tasks** | N√∫mero de tasks |

### 4.4 Identificando Problemas

**Data Skew**:
```
Task 0: 10s
Task 1: 10s
Task 2: 120s  <- SKEW!
Task 3: 10s
```

**Solu√ß√£o**: Reparticionar por coluna com melhor distribui√ß√£o.

**Spill to Disk**:
```
Shuffle Spill (Memory): 0 MB
Shuffle Spill (Disk): 500 MB  <- PROBLEMA!
```

**Solu√ß√£o**: Aumentar mem√≥ria dos executors ou reduzir dados em mem√≥ria.

---

## 5. Monitoramento de Semantic Models

### 5.1 Refresh History

**Acessar**:
1. Workspace ‚Üí Semantic Model ‚Üí Settings
2. Aba "Refresh history"

**Informa√ß√µes**:
- Refresh type (Scheduled, Manual, API)
- Status
- Start/End time
- Duration
- Error details

### 5.2 Performance Analyzer

**No Power BI Desktop**:
1. View ‚Üí Performance Analyzer
2. Start recording
3. Refresh visual
4. Analisar tempo de cada opera√ß√£o

**M√©tricas**:
- DAX query time
- Visual display time
- Other time

### 5.3 DMV Queries (Advanced)

**Conectar via SSMS**:
```
Server: powerbi://api.powerbi.com/v1.0/myorg/[workspace-name]
Database: [dataset-name]
```

**Query de Exemplo**:
```sql
-- Ver √∫ltimas queries executadas
SELECT 
    COMMAND_TEXT,
    COMMAND_START_TIME,
    COMMAND_END_TIME,
    COMMAND_CPU_TIME_MS,
    COMMAND_ELAPSED_TIME_MS
FROM $SYSTEM.DISCOVER_COMMANDS
ORDER BY COMMAND_START_TIME DESC;
```

---

## 6. Configurar Alertas

### 6.1 Alertas de Pipeline

**Configura√ß√£o**:
1. Pipeline ‚Üí Settings ‚Üí Alerts
2. Configurar condi√ß√µes:
   - On failure
   - On success
   - On completion
3. Adicionar destinat√°rios (emails)

**Exemplo de Configura√ß√£o**:
```json
{
  "alertType": "OnFailure",
  "recipients": [
    "data-team@company.com",
    "manager@company.com"
  ],
  "subject": "Pipeline Failed: Daily_Sales_ETL",
  "includeDetails": true
}
```

### 6.2 Data Activator

**Quando usar**: Alertas baseados em dados (n√£o apenas status de execu√ß√£o).

**Cen√°rios**:
- M√©trica de neg√≥cio atinge threshold
- N√∫mero de erros em log excede limite
- Dados de streaming indicam anomalia

**Configura√ß√£o**:

```mermaid
graph LR
    A[Data Source] --> B[Data Activator]
    B --> C{Condition Met?}
    C -->|Yes| D[Trigger Action]
    C -->|No| E[Continue Monitoring]
    
    D --> F[Send Email]
    D --> G[Teams Message]
    D --> H[Power Automate]
    
    style A fill:#e8f5e9
    style B fill:#e3f2fd
    style D fill:#fff4e1
```

**Exemplo de Trigger**:
```
Data Source: KQL Database (error_logs table)
Condition: error_count > 100 in last 5 minutes
Action: Send Teams message to #data-alerts channel
Message: "‚ö†Ô∏è High error rate detected: {error_count} errors in last 5 min"
```

### 6.3 Alertas via Power Automate

**Integra√ß√£o**:
1. Pipeline ‚Üí Add activity ‚Üí Web
2. Chamar webhook do Power Automate
3. Power Automate processa e envia alerta customizado

**Exemplo de Flow**:
```
Trigger: HTTP request (webhook)
Action 1: Parse JSON (pipeline details)
Action 2: Condition (if status = failed)
Action 3: Send Teams adaptive card
Action 4: Create incident in ServiceNow
```

---

## 7. M√©tricas e KPIs de Monitoramento

### 7.1 SLA Tracking

| M√©trica | Descri√ß√£o | Target |
|---------|-----------|--------|
| **Pipeline Success Rate** | % de execu√ß√µes bem-sucedidas | > 99% |
| **Average Duration** | Tempo m√©dio de execu√ß√£o | < 30 min |
| **P95 Duration** | 95¬∫ percentil de dura√ß√£o | < 45 min |
| **Time to Detection** | Tempo at√© detectar falha | < 5 min |
| **Time to Resolution** | Tempo at√© resolver falha | < 2 hours |

### 7.2 Dashboard de Monitoramento

**Criar no Power BI**:

```
Data Source: Fabric Monitoring Hub (via API)
Visuals:
- Card: Success Rate (last 24h)
- Line Chart: Pipeline durations over time
- Table: Recent failures with error messages
- Bar Chart: Top 10 longest running pipelines
- Gauge: SLA compliance
```

---

## 8. Logs e Troubleshooting

### 8.1 Tipos de Logs

| Tipo | Onde Encontrar | O que Cont√©m |
|------|----------------|--------------|
| **Pipeline Logs** | Monitoring Hub ‚Üí Pipeline ‚Üí Activity | Input/Output, Errors |
| **Notebook Logs** | Monitoring Hub ‚Üí Notebook ‚Üí Spark UI | Spark logs, stdout, stderr |
| **Dataflow Logs** | Dataflow ‚Üí Refresh history | Query diagnostics |
| **System Logs** | Capacity Metrics App | Capacity usage, throttling |

### 8.2 Troubleshooting Common Issues

#### Pipeline Timeout

**Sintoma**: Pipeline cancela ap√≥s X horas

**Causa**: Timeout configurado muito baixo

**Solu√ß√£o**:
```json
{
  "policy": {
    "timeout": "02:00:00"  // Aumentar timeout
  }
}
```

#### Out of Memory (Notebook)

**Sintoma**: `OutOfMemoryError` no Spark

**Causa**: Dados muito grandes para mem√≥ria dispon√≠vel

**Solu√ß√£o**:
```python
# Reduzir dados em mem√≥ria
df.unpersist()

# Ou aumentar parti√ß√µes
df = df.repartition(400)

# Ou usar Spark pool maior
```

#### Dataflow Refresh Failure

**Sintoma**: Dataflow falha com "Query timeout"

**Causa**: Query muito complexa ou fonte lenta

**Solu√ß√£o**:
- Simplificar transforma√ß√µes
- Habilitar query folding
- Aumentar timeout da fonte

---

## 9. Best Practices - Monitoramento

### ‚úÖ Proativo

1. **Configure Alertas**:
   - Sempre configure alertas para pipelines cr√≠ticos
   - Use Data Activator para m√©tricas de neg√≥cio
   - Defina SLAs claros

2. **Dashboards**:
   - Crie dashboard de monitoramento centralizado
   - Monitore tend√™ncias (n√£o apenas status atual)
   - Compartilhe com stakeholders

3. **Logging**:
   - Log eventos importantes em tabelas
   - Inclua contexto (RunID, timestamp, par√¢metros)
   - Retenha logs por per√≠odo adequado (30-90 dias)

### ‚úÖ Reativo

1. **Troubleshooting**:
   - Sempre verifique Monitoring Hub primeiro
   - Use Spark UI para problemas de performance
   - Analise logs completos (n√£o apenas mensagem de erro)

2. **Documenta√ß√£o**:
   - Documente problemas comuns e solu√ß√µes
   - Crie runbooks para incidentes
   - Mantenha knowledge base atualizada

---

## Refer√™ncias e Recursos

1. [Monitoring Hub](https://learn.microsoft.com/fabric/data-factory/monitor-hub)
2. [Pipeline Alerts](https://learn.microsoft.com/fabric/data-factory/pipeline-alerts)
3. [Data Activator](https://learn.microsoft.com/fabric/data-activator/data-activator-overview)
4. [Spark UI Guide](https://spark.apache.org/docs/latest/web-ui.html)
5. [Guia de Estudo DP-700](https://learn.microsoft.com/credentials/certifications/resources/study-guides/dp-700)

---

## Pontos-Chave para o Exame DP-700

üéØ **Memorize**:
- **Monitoring Hub**: Ponto centralizado para monitorar tudo
- **Pipeline Alerts**: On failure, On success, On completion
- **Data Activator**: Alertas baseados em dados (n√£o apenas status)
- **Spark UI**: Troubleshooting de performance de notebooks
- **Refresh History**: Monitorar Dataflows e Semantic Models
- **DMV Queries**: An√°lise avan√ßada de Semantic Models
- **SLA Metrics**: Success rate, duration, P95

üéØ **Entenda**:
- Como acessar logs detalhados de cada tipo de item
- Diferen√ßa entre alertas de pipeline e Data Activator
- Como usar Spark UI para identificar data skew
- M√©tricas importantes de Copy Activity
- Como configurar alertas proativos
- Troubleshooting de problemas comuns

